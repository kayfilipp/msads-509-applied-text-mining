{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"C:/Users/fkrasovsky/OneDrive - Allvue Systems/Documents/usd/msads-509/Module-1-Scraping-APIs-and Research Questions/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0ac17",
   "metadata": {},
   "source": [
    "#### Lyrics Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c907d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>105\\n</td>\n",
       "      <td>\\n \\n \\n \\n Why the hell are we waitin' in lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>2000 Miles\\n</td>\n",
       "      <td>\\n \\n \\n \\n He's gone 2000 miles\\n It's very f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>All Star\\n</td>\n",
       "      <td>\\n \\n \\n \\n Somebody once told me the world is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>Always Gets Her Way\\n</td>\n",
       "      <td>\\n \\n \\n \\n I know she likes her magazines\\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>Beautiful Bomb\\n</td>\n",
       "      <td>\\n \\n \\n \\n Your asteroids bounce off her like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist              song_name  \\\n",
       "0  smash mouth                  105\\n   \n",
       "1  smash mouth           2000 Miles\\n   \n",
       "2  smash mouth             All Star\\n   \n",
       "3  smash mouth  Always Gets Her Way\\n   \n",
       "4  smash mouth       Beautiful Bomb\\n   \n",
       "\n",
       "                                                text  \n",
       "0  \\n \\n \\n \\n Why the hell are we waitin' in lin...  \n",
       "1  \\n \\n \\n \\n He's gone 2000 miles\\n It's very f...  \n",
       "2  \\n \\n \\n \\n Somebody once told me the world is...  \n",
       "3  \\n \\n \\n \\n I know she likes her magazines\\n \\...  \n",
       "4  \\n \\n \\n \\n Your asteroids bounce off her like...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "# point at the folder containing lyrics for all our artists\n",
    "lyrics_path = data_location+'/'+lyrics_folder\n",
    "artists = os.listdir(lyrics_path)\n",
    "\n",
    "#iterate over both artists, get a list of all the text files containing their songs, read them into separate dataframes.\n",
    "#we can create dynamic variable names for the dfs using the globals function.\n",
    "\n",
    "song_artist = []\n",
    "song_names = []\n",
    "song_lyrics = []\n",
    "\n",
    "for artist in artists:\n",
    "    \n",
    "    artist_path = lyrics_path + artist\n",
    "    songs = os.listdir(artist_path)\n",
    "\n",
    "    # get each song for our artist, read it in as a string, and append it to a list.\n",
    "    for song in songs:\n",
    "        song_path = artist_path + '/' + song\n",
    "        \n",
    "        with open(song_path) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # we also need a meaningful way to extract the song name. the rule for \n",
    "        # this dataset is that the title is separated by at least one carriage return,\n",
    "        # and we also know that it's always on the first line.\n",
    "        \n",
    "        this_song = lines[0]\n",
    "        this_lyrics = ' '.join(lines[1:])\n",
    "        \n",
    "        song_artist.append(artist)\n",
    "        song_names.append(this_song)\n",
    "        song_lyrics.append(this_lyrics)\n",
    "\n",
    "d = {\n",
    "        'artist':song_artist,\n",
    "        'song_name': song_names,\n",
    "        'text': song_lyrics\n",
    "    }\n",
    "\n",
    "#turn into a datafreame and do a sanity check\n",
    "df = pd.DataFrame(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9210",
   "metadata": {},
   "source": [
    "#### Twitter Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm whatever SHHS'21 Not on Twitter much..</td>\n",
       "      <td>smashmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>smashmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17 | i game occasionally | matching with @batb...</td>\n",
       "      <td>smashmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22 He/Him Spotted Hyena British Autistic I lik...</td>\n",
       "      <td>smashmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26 ‚Ä¢ Guy who games ‚Ä¢ BotW glitch enthusiast ‚Ä¢ ...</td>\n",
       "      <td>smashmouth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      artist\n",
       "0         I'm whatever SHHS'21 Not on Twitter much..  smashmouth\n",
       "1                                                NaN  smashmouth\n",
       "2  17 | i game occasionally | matching with @batb...  smashmouth\n",
       "3  22 He/Him Spotted Hyena British Autistic I lik...  smashmouth\n",
       "4  26 ‚Ä¢ Guy who games ‚Ä¢ BotW glitch enthusiast ‚Ä¢ ...  smashmouth"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the twitter data\n",
    "#read in the twitter data\n",
    "twitter_path = data_location+'/'+twitter_folder\n",
    "descriptions = []\n",
    "\n",
    "for file in os.listdir(twitter_path):\n",
    "    if (file.split('.')[1]=='tsv'):\n",
    "        \n",
    "        artist_name = file.split('_')[0]\n",
    "        follower_data = pd.read_csv(twitter_path+'/'+file,sep='\\t')\n",
    "        follower_data['artist'] = artist_name\n",
    "        follower_desc = follower_data[['description','artist']]\n",
    "        descriptions.append(follower_desc)\n",
    "        \n",
    "twitter_df = pd.DataFrame(descriptions[0].append(descriptions[1], \n",
    "                  ignore_index = True),columns=['description','artist'])\n",
    "twitter_df = twitter_df.rename(columns={\"description\": \"text\"})\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af9e7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "sentiment = {}\n",
    "\n",
    "#we know that the first 34 lines are metadata, so we skip them.\n",
    "\n",
    "with open(positive_words_file) as file:\n",
    "    words = file.readlines()[35:]\n",
    "    \n",
    "    #remove newline characters\n",
    "    for i in range(0,len(words)):\n",
    "        words[i] = words[i].strip(\"\\n\")\n",
    "        sentiment[words[i]] = 1 \n",
    "        \n",
    "with open(negative_words_file) as file:\n",
    "    words = file.readlines()[35:]\n",
    "    \n",
    "    #remove newline characters\n",
    "    for i in range(0,len(words)):\n",
    "        words[i] = words[i].strip(\"\\n\")\n",
    "        sentiment[words[i]] = -1 \n",
    "        \n",
    "# dealing with the tidytext sentiments is unique because of its dataframe structure.\n",
    "def sentiment_convert(sentiment):\n",
    "    if sentiment==\"positive\":\n",
    "        return 1\n",
    "    return -1\n",
    "# convert sentiment into 1 and -1\n",
    "tidy = pd.read_csv(tidy_text_file,sep=\"\\t\")\n",
    "tidy['num_sentiment'] = tidy['sentiment'].map(sentiment_convert)\n",
    "\n",
    "# update the sentiment dictionary with the tidy words.\n",
    "tidy_dict = dict(zip(tidy['word'], tidy['num_sentiment']))\n",
    "sentiment.update(tidy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "664f8d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>text</th>\n",
       "      <th>sentment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>105\\n</td>\n",
       "      <td>\\n \\n \\n \\n Why the hell are we waitin' in lin...</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>2000 Miles\\n</td>\n",
       "      <td>\\n \\n \\n \\n He's gone 2000 miles\\n It's very f...</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>All Star\\n</td>\n",
       "      <td>\\n \\n \\n \\n Somebody once told me the world is...</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.028736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>Always Gets Her Way\\n</td>\n",
       "      <td>\\n \\n \\n \\n I know she likes her magazines\\n \\...</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.071006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smash mouth</td>\n",
       "      <td>Beautiful Bomb\\n</td>\n",
       "      <td>\\n \\n \\n \\n Your asteroids bounce off her like...</td>\n",
       "      <td>-0.008197</td>\n",
       "      <td>-0.008197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist              song_name  \\\n",
       "0  smash mouth                  105\\n   \n",
       "1  smash mouth           2000 Miles\\n   \n",
       "2  smash mouth             All Star\\n   \n",
       "3  smash mouth  Always Gets Her Way\\n   \n",
       "4  smash mouth       Beautiful Bomb\\n   \n",
       "\n",
       "                                                text  sentment_score  \\\n",
       "0  \\n \\n \\n \\n Why the hell are we waitin' in lin...        0.008929   \n",
       "1  \\n \\n \\n \\n He's gone 2000 miles\\n It's very f...        0.008547   \n",
       "2  \\n \\n \\n \\n Somebody once told me the world is...        0.028736   \n",
       "3  \\n \\n \\n \\n I know she likes her magazines\\n \\...        0.071006   \n",
       "4  \\n \\n \\n \\n Your asteroids bounce off her like...       -0.008197   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.008929  \n",
       "1         0.008547  \n",
       "2         0.028736  \n",
       "3         0.071006  \n",
       "4        -0.008197  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a function that scores the sentiment for a body of text by dividing the sum of sentiment points by\n",
    "#the total number of words.\n",
    "def score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in sentiment:\n",
    "            sentiment_score += sentiment[word]\n",
    "            \n",
    "    return sentiment_score / len(bag_of_words)\n",
    "\n",
    "df['sentiment_score'] = df['text'].map(score)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2193b8",
   "metadata": {},
   "source": [
    "#### Insight 1: Average sentiment per song by artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29db0cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "smash mouth    0.017300\n",
       "wallows        0.011347\n",
       "Name: sentiment_score, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"artist\")['sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085e47e",
   "metadata": {},
   "source": [
    "#### Insight 2: Highest and Lowest Sentiments for Smash Mouth\n",
    "we could have probably just run this code twice, but let's do a function anyway!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "183b598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest-sentiment song for smash mouth is: Can't Get Enough Of You Baby with a score of 0.1828793774319066\n",
      "The lowest-sentiment song for smash mouth is: Sorry About Your Penis with a score of -0.07991803278688525\n"
     ]
    }
   ],
   "source": [
    "def highLowSongs(df,artist):\n",
    "    \n",
    "    sm_max = df.query(f\"artist=='{artist}'\")['sentiment_score'].idxmax()\n",
    "    sm_max_song = df.iloc[sm_max]['song_name'].strip(\"\\n\")\n",
    "    sm_max_score = df.iloc[sm_max]['sentiment_score']\n",
    "    \n",
    "    sm_min = df.query(f\"artist=='{artist}'\")['sentiment_score'].idxmin()\n",
    "    sm_min_song = df.iloc[sm_min]['song_name'].strip(\"\\n\")\n",
    "    sm_min_score = df.iloc[sm_min]['sentiment_score']\n",
    "    \n",
    "    print(f\"The highest-sentiment song for {artist} is: {sm_max_song} with a score of {sm_max_score}\")\n",
    "    print(f\"The lowest-sentiment song for {artist} is: {sm_min_song} with a score of {sm_min_score}\")\n",
    "    \n",
    "highLowSongs(df,'smash mouth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c858d6d",
   "metadata": {},
   "source": [
    "#### Insight 3: Highest and Lowest Sentiments for Wallows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94c336dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest-sentiment song for wallows is: Let The Sun In with a score of 0.10894941634241245\n",
      "The lowest-sentiment song for wallows is: Do Not Wait with a score of -0.06964285714285715\n"
     ]
    }
   ],
   "source": [
    "highLowSongs(df,'wallows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8334f4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "**Q: Overall, which artist has the higher average sentiment per song?**\n",
    "\n",
    "A: Smash Mouth has a slightly higher sentiment score, on average, compared to Wallows, which is in line with subject matter expertise that the Wallows write music for people that are too shy to say hello to their crush at a house party.\n",
    "\n",
    "---\n",
    "\n",
    "**Q: For your first artist, what songs have the highest and lowest sentiments? Print those songs to the screen.**\n",
    "\n",
    "A: For smash mouth, Can't get enough of you baby has the highest sentiment, while the lowest-ranking song is Sorry About Your Penis.\n",
    "\n",
    "---\n",
    "\n",
    "**Q: For your second artist, what songs have the highest and lowest sentiments? Print those songs to the screen.**\n",
    "\n",
    "For the Wallows, Let the Sun In has the highest sentiment while Do Not Wait has the lowest sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "**Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78be1ed",
   "metadata": {},
   "source": [
    "#### Histogram for Smash Mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "777d6e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.query(\"artist=='smash mouth'\")['sentiment_score'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd9145",
   "metadata": {},
   "source": [
    "#### Histogram for Wallows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f6cd0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.query(\"artist=='wallows'\")['sentiment_score'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe644d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1185c3",
   "metadata": {},
   "source": [
    "#### Step 1: Scrape a library of emojis and sentiment scores\n",
    "for this, we can use a small lexicon created by <a href='http://kt.ijs.si/data/Emoji_sentiment_ranking/'>Novak, et al</a> and parse the webpage for a handy list of 80 emojis and round up their sentiment scores to 1 or -1. We use BS to go through each row and identify the emoji and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35143f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr class=\"tableizer-firstrow\">\n",
      "<th>Char</th><th>Image<br/>[twemoji]</th><th>Unicode<br/>codepoint</th><th>Occurrences<br/>[5...max]</th><th>Position<br/>[0...1]</th><th>Neg<br/>[0...1]</th><th>Neut<br/>[0...1]</th><th>Pos<br/>[0...1]</th><th>Sentiment score<br/>[-1...+1]</th><th>Sentiment bar<br/>(c.i. 95%)</th><th>Unicode name</th><th>Unicode block</th></tr>]\n"
     ]
    }
   ],
   "source": [
    "emojis = requests.get('http://kt.ijs.si/data/Emoji_sentiment_ranking/')\n",
    "soup = BeautifulSoup(emojis.text,'html.parser')\n",
    "emoji_data = soup.find_all(\"tr\")\n",
    "print(emoji_data[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef05458e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'üòÇ': 1, '‚ù§': 1, '‚ô•': 1, 'üòç': 1,\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_lexicon = {}\n",
    "\n",
    "#iterate over our BS object and extract the icon and sentiment score for each emoji.\n",
    "#coerce the sentiment to 1 or -1.\n",
    "for emoji in emoji_data[1:]:\n",
    "    these_columns = emoji.find_all(\"td\")\n",
    "    this_icon = these_columns[0].text\n",
    "    this_sentiment = float(these_columns[8].text)\n",
    "    \n",
    "    if (this_sentiment >= 0):\n",
    "        this_sentiment = 1 \n",
    "    else:\n",
    "        this_sentiment = -1\n",
    "    \n",
    "    emoji_lexicon[this_icon] = this_sentiment\n",
    "    \n",
    "#print a small sample of our work as a sanity check \n",
    "str(emoji_lexicon)[0:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958b65c",
   "metadata": {},
   "source": [
    "#### Step 2: Score our Twitter Data with the emoji Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in emoji_lexicon:\n",
    "            sentiment_score += emoji_lexicon[word]\n",
    "            \n",
    "    return sentiment_score / len(bag_of_words)\n",
    "\n",
    "#coerce text to str first to handle float edge cases.\n",
    "twitter_df['text'] = twitter_df['text'].astype(str)\n",
    "twitter_df['emoji_sentiment'] = twitter_df['text'].map(emoji_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af390da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>artist</th>\n",
       "      <th>emoji_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71416</th>\n",
       "      <td>üé† üåù üé†</td>\n",
       "      <td>wallowsmusic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98405</th>\n",
       "      <td>üíï</td>\n",
       "      <td>wallowsmusic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117592</th>\n",
       "      <td>üåÜ</td>\n",
       "      <td>wallowsmusic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90535</th>\n",
       "      <td>üêæ</td>\n",
       "      <td>wallowsmusic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107499</th>\n",
       "      <td>üè°</td>\n",
       "      <td>wallowsmusic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text        artist  emoji_sentiment\n",
       "71416   üé† üåù üé†  wallowsmusic              1.0\n",
       "98405       üíï  wallowsmusic              1.0\n",
       "117592      üåÜ  wallowsmusic              1.0\n",
       "90535       üêæ  wallowsmusic              1.0\n",
       "107499      üè°  wallowsmusic              1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see how we did!\n",
    "twitter_df.sort_values('emoji_sentiment',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33413cc7",
   "metadata": {},
   "source": [
    "#### Step 3. Get average score by artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9a82fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "smashmouth      0.008093\n",
       "wallowsmusic    0.016267\n",
       "Name: emoji_sentiment, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.groupby(\"artist\")['emoji_sentiment'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fad59c",
   "metadata": {},
   "source": [
    "#### Step 4. Get most common positive emoji by artist\n",
    "for this part, we employ a strategy of cloning a dictionary with only the positive emojis and cycling through our twitter_df, creating a list of emojis for each data point, merging the lists together, and creating a counter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7d0861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emojis = {}\n",
    "for k,v in emoji_lexicon.items():\n",
    "    if v == 1:\n",
    "        positive_emojis[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_emojis(text):\n",
    "    return [t for t in word_tokenize(text.lower()) if t in positive_emojis]\n",
    "\n",
    "def combine_tokens(tokens):\n",
    "    out = []\n",
    "    for token_list in tokens:\n",
    "        out = out + token_list\n",
    "    return out\n",
    "\n",
    "#place all the emojis for each bio into a list \n",
    "twitter_df['pos_emojis'] = twitter_df['text'].map(get_positive_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db158c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of emojis for each artist. notice the second expression where we reaffirm\n",
    "#that there are only two types of bands - smash mouth, and not smash mouth.\n",
    "smashmouth = combine_tokens(twitter_df.query(\"artist=='smashmouth'\")['pos_emojis'])\n",
    "wallows = combine_tokens(twitter_df.query(\"artist!='smashmouth'\")['pos_emojis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92eb93",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists? \n",
    "\n",
    "A: Smashmouth has an average score of .008 while wallows has an average score of 0.016.\n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji? \n",
    "\n",
    "A: See below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc15c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('‚ú®', 294)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(smashmouth).most_common(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb63962",
   "metadata": {},
   "source": [
    "the most common emoji in a twitter bio for a smash mouth fan is very appropriate, since most of them personally identify as an all-star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f8134b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('‚†Ä', 932), ('‚ô°', 626)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(wallows).most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d6fa7",
   "metadata": {},
   "source": [
    "Wallows followers tend to use white hearts the most often out of all positive emojis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
